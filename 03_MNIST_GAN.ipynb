{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as utils\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "# 0~1로 standardize -> G에서 tanh 써야함\n",
    "standardizator = transforms.Compose([\n",
    "transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "# MNIST dataset\n",
    "train_data = dsets.MNIST(root='data/', train=True, transform=standardizator, download=True)\n",
    "test_data  = dsets.MNIST(root='data/', train=False, transform=standardizator, download=True)\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "test_data_loader  = torch.utils.data.DataLoader(test_data, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_mini_batch_img, example_mini_batch_label  = next(iter(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input notse generator for Generator\n",
    "def input_noise_generator(batch_size, dim):\n",
    "    return torch.randn(batch_size, dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, dim_input, dim_hidden_1, dim_hidden_2, dim_output):\n",
    "        super(Generator, self).__init__()\n",
    "        self.layer_1 = nn.Linear(dim_input, dim_hidden_1)\n",
    "        self.layer_2 = nn.Linear(dim_hidden_1, dim_hidden_2)\n",
    "        self.layer_3 = nn.Linear(dim_hidden_2, dim_output)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer_1(x))\n",
    "        x = F.dropout(x, p=0.1)\n",
    "        x = F.relu(self.layer_2(x))\n",
    "        x = F.dropout(x, p=0.1)\n",
    "        x = F.tanh(self.layer_3(x))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, dim_input, dim_hidden_1, dim_hidden_2, dim_output):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer_1 = nn.Linear(dim_input, dim_hidden_1)\n",
    "        self.layer_2 = nn.Linear(dim_hidden_1, dim_hidden_2)\n",
    "        self.layer_3 = nn.Linear(dim_hidden_2, dim_output)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer_1(x))\n",
    "        x = F.dropout(x, p=0.1)\n",
    "        x = F.relu(self.layer_2(x))\n",
    "        x = F.dropout(x, p=0.1)\n",
    "        x = F.relu(self.layer_3(x))\n",
    "        return x\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_torch",
   "language": "python",
   "name": "py36_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
